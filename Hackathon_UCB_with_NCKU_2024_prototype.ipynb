{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Q6ka6QPl30jC",
   "metadata": {
    "id": "Q6ka6QPl30jC",
    "tags": []
   },
   "source": [
    "# **Set up Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6881e013-10f7-429e-b765-ee369b222025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "pip install -qU langchain-nomic\n",
    "pip install -U langchain-chroma\n",
    "pip install langchain-openai\n",
    "pip install --upgrade --quiet langchain-community gpt4all\n",
    "pip install --upgrade --quiet  gpt4all > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520d840-fcf6-4458-b85c-8a2ff80a34eb",
   "metadata": {
    "id": "8520d840-fcf6-4458-b85c-8a2ff80a34eb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain-nomic langchain_community tiktoken langchainhub chromadb langchain langgraph tavily-python gpt4all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P-DcP1eMqB57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4669,
     "status": "ok",
     "timestamp": 1734189079010,
     "user": {
      "displayName": "Donald Lu",
      "userId": "11995103325229826253"
     },
     "user_tz": -480
    },
    "id": "P-DcP1eMqB57",
    "outputId": "92ffd90a-ea2c-405a-d376-7a99887403db",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain-nvidia-ai-endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3w3FAzN4ww7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10663,
     "status": "ok",
     "timestamp": 1718723978732,
     "user": {
      "displayName": "Donald Lu",
      "userId": "11995103325229826253"
     },
     "user_tz": -480
    },
    "id": "3w3FAzN4ww7c",
    "outputId": "d9222fcd-f1b6-4c5e-bfe9-aad3e1ac7037",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jfjIWq6VEpjs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7624,
     "status": "ok",
     "timestamp": 1718679543773,
     "user": {
      "displayName": "Donald Lu",
      "userId": "11995103325229826253"
     },
     "user_tz": -480
    },
    "id": "jfjIWq6VEpjs",
    "outputId": "1a431bc2-0d48-4232-bfd1-4ac5b7eae162",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bFmCQ_6HKLLY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17209,
     "status": "ok",
     "timestamp": 1718724000928,
     "user": {
      "displayName": "Donald Lu",
      "userId": "11995103325229826253"
     },
     "user_tz": -480
    },
    "id": "bFmCQ_6HKLLY",
    "outputId": "3c6813f1-501f-4271-b834-a563752d08c4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xpJJWIfy6urA",
   "metadata": {
    "id": "xpJJWIfy6urA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "nOGFVglKqQ_Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1734190649937,
     "user": {
      "displayName": "Donald Lu",
      "userId": "11995103325229826253"
     },
     "user_tz": -480
    },
    "id": "nOGFVglKqQ_Y",
    "outputId": "e82a06c7-5a9b-4d7e-cf3a-6af188c28aca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 載入 .env 檔案\n",
    "load_dotenv()\n",
    "\n",
    "# 取得 API Key\n",
    "api_key = os.getenv(\"NVIDIA_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "lKvcHZmdyAVd",
   "metadata": {
    "id": "lKvcHZmdyAVd",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT4AllEmbeddings(model_name='all-MiniLM-L6-v2.gguf2.f16.gguf', n_threads=None, device='cpu', gpt4all_kwargs={'allow_download': 'True'}, client=<gpt4all.gpt4all.Embed4All object at 0x7f06951858d0>)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from langchain.schema import Document\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "import gradio as gr\n",
    "import time\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "# Initialize GPT4AllEmbeddings\n",
    "model_name = \"all-MiniLM-L6-v2.gguf2.f16.gguf\"\n",
    "gpt4all_kwargs = {'allow_download': 'True'}\n",
    "GPT4AllEmbeddings(\n",
    "    model_name=model_name,\n",
    "    gpt4all_kwargs=gpt4all_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "4EpdTeNlDH5q",
   "metadata": {
    "id": "4EpdTeNlDH5q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Are there specific formulations of Simvastatin designed for patients with genetic risks?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38AKgF143sCQ",
   "metadata": {
    "id": "38AKgF143sCQ"
   },
   "source": [
    "# **Set Up Agents and Tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tucOfSr16yt_",
   "metadata": {
    "id": "tucOfSr16yt_"
   },
   "source": [
    "## Query rewriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "b5a372b6-1fb6-4fe1-ab0b-1f4aa3d8eba4",
   "metadata": {
    "id": "PcA-NQm6tJTz",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code took 0.83 seconds to execute.\n",
      "Simvastatin: genetic-risks, formulations, drug-interactions, pharmacodynamics, mechanism-of-action\n"
     ]
    }
   ],
   "source": [
    "# VectorStoreRewriter\n",
    "\n",
    "model_id = \"meta/llama-3.3-70b-instruct\"\n",
    "\n",
    "# LLM\n",
    "llm = ChatNVIDIA(model=model_id, temperature=0)\n",
    "\n",
    "prompt_vs = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a vectorstore query rewriter, and you'll receive a question from the patient and a list of tags and drug names. You'll have to extract the drug name and possibly useful tags from the lists.\n",
    "- Comprehend the question and extract \"one drug\" from the question\n",
    "- Comprehend the question and select the tags from the list and store them in the string\n",
    "- Return the drug: string of tags pair only, without any explanation\n",
    "\n",
    "## drug names\n",
    "\n",
    "Etanercept\n",
    "Alteplase\n",
    "Darbepoetin alfa\n",
    "Goserelin\n",
    "Pegfilgrastim\n",
    "Asparaginase Escherichia coli\n",
    "Desmopressin\n",
    "Glucagon\n",
    "Insulin glargine\n",
    "Rasburicase\n",
    "Adalimumab\n",
    "Pegaspargase\n",
    "Infliximab\n",
    "Trastuzumab\n",
    "Rituximab\n",
    "Streptokinase\n",
    "Filgrastim\n",
    "Coagulation Factor IX (Recombinant)\n",
    "Octreotide\n",
    "Oxytocin\n",
    "Bevacizumab\n",
    "Ascorbic acid\n",
    "Calcitriol\n",
    "Riboflavin\n",
    "Thiamine\n",
    "Ergocalciferol\n",
    "Folic acid\n",
    "Pyridoxine\n",
    "Fluvoxamine\n",
    "Ramipril\n",
    "Flunisolide\n",
    "Lorazepam\n",
    "Bortezomib\n",
    "Carbidopa\n",
    "Fluconazole\n",
    "Oseltamivir\n",
    "Erythromycin\n",
    "Hydroxocobalamin\n",
    "Pyrimethamine\n",
    "Azithromycin\n",
    "Torasemide\n",
    "Citalopram\n",
    "Moxifloxacin\n",
    "Nevirapine\n",
    "Cladribine\n",
    "Mesalazine\n",
    "Cabergoline\n",
    "Dapsone\n",
    "Phenytoin\n",
    "Doxycycline\n",
    "Clotrimazole\n",
    "Cycloserine\n",
    "Metoprolol\n",
    "Lidocaine\n",
    "Bleomycin\n",
    "Chlorambucil\n",
    "Morphine\n",
    "Bupivacaine\n",
    "Tenofovir disoproxil\n",
    "Tranexamic acid\n",
    "Chlorthalidone\n",
    "Valproic acid\n",
    "Acetaminophen\n",
    "Gefitinib\n",
    "Codeine\n",
    "Piperacillin\n",
    "Amitriptyline\n",
    "Hydromorphone\n",
    "Ethambutol\n",
    "Metformin\n",
    "Methadone\n",
    "Olanzapine\n",
    "Atenolol\n",
    "Omeprazole\n",
    "Pyrazinamide\n",
    "Cetirizine\n",
    "Tioguanine\n",
    "Methylergometrine\n",
    "Mefloquine\n",
    "Sulfadiazine\n",
    "Vinorelbine\n",
    "Anidulafungin\n",
    "Clozapine\n",
    "Levonorgestrel\n",
    "Timolol\n",
    "Trihexyphenidyl\n",
    "Palonosetron\n",
    "Amlodipine\n",
    "Carbimazole\n",
    "Digoxin\n",
    "Zoledronic acid\n",
    "Griseofulvin\n",
    "Mupirocin\n",
    "Ampicillin\n",
    "Phenoxymethylpenicillin\n",
    "Spironolactone\n",
    "Allopurinol\n",
    "Ceftazidime\n",
    "Trimethoprim\n",
    "Gemcitabine\n",
    "Entecavir\n",
    "Betamethasone\n",
    "Chloramphenicol\n",
    "Levothyroxine\n",
    "Loratadine\n",
    "Quinine\n",
    "Fluoxetine\n",
    "Chlorpromazine\n",
    "Amikacin\n",
    "Lenalidomide\n",
    "Cefotaxime\n",
    "Zidovudine\n",
    "Oxycodone\n",
    "Flutamide\n",
    "Haloperidol\n",
    "Ritonavir\n",
    "Vancomycin\n",
    "Cisplatin\n",
    "Albendazole\n",
    "Caspofungin\n",
    "Oxaliplatin\n",
    "Erlotinib\n",
    "Cyclophosphamide\n",
    "Ciprofloxacin\n",
    "Vincristine\n",
    "Fluorouracil\n",
    "Pyridostigmine\n",
    "Propylthiouracil\n",
    "Lamotrigine\n",
    "Methotrexate\n",
    "Carbamazepine\n",
    "Vinblastine\n",
    "Propranolol\n",
    "Atropine\n",
    "Valaciclovir\n",
    "Lactulose\n",
    "Voriconazole\n",
    "Enalapril\n",
    "Ethosuximide\n",
    "Amiloride\n",
    "Oxytetracycline\n",
    "Thiopental\n",
    "Linezolid\n",
    "Ivermectin\n",
    "Medroxyprogesterone acetate\n",
    "Chloroquine\n",
    "Ethionamide\n",
    "Bisoprolol\n",
    "Amodiaquine\n",
    "Rifabutin\n",
    "Imatinib\n",
    "Fluphenazine\n",
    "Testosterone\n",
    "Efavirenz\n",
    "Prednisone\n",
    "Mebendazole\n",
    "Nystatin\n",
    "Magnesium sulfate\n",
    "Latanoprost\n",
    "Verapamil\n",
    "Nilutamide\n",
    "Epinephrine\n",
    "Sumatriptan\n",
    "Cefixime\n",
    "Aprepitant\n",
    "Tamoxifen\n",
    "Benzyl benzoate\n",
    "Losartan\n",
    "Amphotericin B\n",
    "Warfarin\n",
    "Midazolam\n",
    "Tobramycin\n",
    "Fludrocortisone\n",
    "Fluorescein\n",
    "Daunorubicin\n",
    "Furosemide\n",
    "Nitrofurantoin\n",
    "Naltrexone\n",
    "Lamivudine\n",
    "Diethylcarbamazine\n",
    "Apomorphine\n",
    "Paroxetine\n",
    "Norethisterone\n",
    "Lisinopril\n",
    "Risperidone\n",
    "Pentamidine\n",
    "Hydrocortisone\n",
    "Mannitol\n",
    "Deferoxamine\n",
    "Dolasetron\n",
    "Clopidogrel\n",
    "Tetracycline\n",
    "Meropenem\n",
    "Potassium chloride\n",
    "Irinotecan\n",
    "Methimazole\n",
    "Mometasone\n",
    "Clavulanic acid\n",
    "Etoposide\n",
    "Sulfasalazine\n",
    "Gentamicin\n",
    "Colistin\n",
    "Indapamide\n",
    "Tropicamide\n",
    "Biperiden\n",
    "Ribavirin\n",
    "Fentanyl\n",
    "Propofol\n",
    "Acetazolamide\n",
    "Natamycin\n",
    "Fosfomycin\n",
    "Diazepam\n",
    "Mifepristone\n",
    "Loperamide\n",
    "Clofazimine\n",
    "Levamisole\n",
    "Dacarbazine\n",
    "Terbinafine\n",
    "Penicillamine\n",
    "Prednisolone\n",
    "Ranitidine\n",
    "Tacrolimus\n",
    "Terbutaline\n",
    "Chlorhexidine\n",
    "Emtricitabine\n",
    "Chlorothiazide\n",
    "Clomifene\n",
    "Isosorbide dinitrate\n",
    "Bumetanide\n",
    "Granisetron\n",
    "Ondansetron\n",
    "Tinidazole\n",
    "Metronidazole\n",
    "Spectinomycin\n",
    "Buprenorphine\n",
    "Misoprostol\n",
    "Salicylic acid\n",
    "Salmeterol\n",
    "Acetylsalicylic acid\n",
    "Fexofenadine\n",
    "Isoniazid\n",
    "Netilmicin\n",
    "Carboplatin\n",
    "Methylprednisolone\n",
    "Telmisartan\n",
    "Methyldopa\n",
    "Dactinomycin\n",
    "Selenium Sulfide\n",
    "Ethinylestradiol\n",
    "Cyclopentolate\n",
    "Formoterol\n",
    "Glycopyrronium\n",
    "Cytarabine\n",
    "Dopamine\n",
    "Azathioprine\n",
    "Doxorubicin\n",
    "Hydrochlorothiazide\n",
    "Salbutamol\n",
    "Hydroxyurea\n",
    "Letrozole\n",
    "Sulfamethoxazole\n",
    "Mercaptopurine\n",
    "Thalidomide\n",
    "Melphalan\n",
    "Rifampicin\n",
    "Abacavir\n",
    "Ibuprofen\n",
    "Benzylpenicillin\n",
    "Praziquantel\n",
    "Amoxicillin\n",
    "Fludarabine\n",
    "Streptomycin\n",
    "Pilocarpine\n",
    "Primaquine\n",
    "Oxamniquine\n",
    "Flucytosine\n",
    "Capecitabine\n",
    "Sertraline\n",
    "Miconazole\n",
    "Cefuroxime\n",
    "Nifedipine\n",
    "Amiodarone\n",
    "Diazoxide\n",
    "Gliclazide\n",
    "Bicalutamide\n",
    "Proguanil\n",
    "Carvedilol\n",
    "Levofloxacin\n",
    "Micafungin\n",
    "Cloxacillin\n",
    "Bupropion\n",
    "Halothane\n",
    "Ofloxacin\n",
    "Itraconazole\n",
    "Procarbazine\n",
    "Arsenic trioxide\n",
    "Kanamycin\n",
    "Phenobarbital\n",
    "Escitalopram\n",
    "Cyclizine\n",
    "Ifosfamide\n",
    "Naloxone\n",
    "Clindamycin\n",
    "Bromocriptine\n",
    "Rifapentine\n",
    "Levetiracetam\n",
    "Clarithromycin\n",
    "Ceftriaxone\n",
    "Anastrozole\n",
    "Ketamine\n",
    "Budesonide\n",
    "Quetiapine\n",
    "Enoxaparin\n",
    "Paclitaxel\n",
    "Metoclopramide\n",
    "Dexamethasone\n",
    "Levodopa\n",
    "Sevoflurane\n",
    "Aripiprazole\n",
    "Clomipramine\n",
    "Docetaxel\n",
    "Ergometrine\n",
    "Dasatinib\n",
    "Darunavir\n",
    "Paliperidone\n",
    "Varenicline\n",
    "Hydralazine\n",
    "Carbetocin\n",
    "Sulfadoxine\n",
    "Insulin detemir\n",
    "Cefazolin\n",
    "Vecuronium\n",
    "Iohexol\n",
    "Calcium\n",
    "Neostigmine\n",
    "Tiotropium\n",
    "Ciclesonide\n",
    "Paromomycin\n",
    "Everolimus\n",
    "Cilastatin\n",
    "Imipenem\n",
    "Lopinavir\n",
    "Tazobactam\n",
    "Deferasirox\n",
    "Valganciclovir\n",
    "Hydroxychloroquine\n",
    "Calcipotriol\n",
    "Nicotinamide\n",
    "Acetic acid\n",
    "Glutaral\n",
    "Nilotinib\n",
    "Permethrin\n",
    "Pretomanid\n",
    "Silver sulfadiazine\n",
    "Iodine\n",
    "Liposomal prostaglandin E1\n",
    "Sodium stibogluconate\n",
    "Abiraterone\n",
    "Acetylcysteine\n",
    "Rivaroxaban\n",
    "Eflornithine\n",
    "Dapagliflozin\n",
    "Apixaban\n",
    "Golimumab\n",
    "Nitrous oxide\n",
    "Xylometazoline\n",
    "Artemether\n",
    "Lumefantrine\n",
    "Potassium Iodide\n",
    "Bendamustine\n",
    "Dalteparin\n",
    "Dimercaprol\n",
    "Niclosamide\n",
    "Raltegravir\n",
    "Triptorelin\n",
    "Diloxanide\n",
    "Nadroparin\n",
    "Deferiprone\n",
    "Ulipristal\n",
    "Asparaginase Erwinia chrysanthemi\n",
    "Aclidinium\n",
    "Enzalutamide\n",
    "Bedaquiline\n",
    "Certolizumab pegol\n",
    "Fluticasone furoate\n",
    "Canagliflozin\n",
    "Afatinib\n",
    "Dolutegravir\n",
    "Sofosbuvir\n",
    "Bisacodyl\n",
    "Ledipasvir\n",
    "Miltefosine\n",
    "Nivolumab\n",
    "Pembrolizumab\n",
    "Empagliflozin\n",
    "Tedizolid phosphate\n",
    "Ceftolozane\n",
    "Ibrutinib\n",
    "Avibactam\n",
    "Edoxaban\n",
    "Umeclidinium\n",
    "Tetracaine\n",
    "Chlortetracycline\n",
    "Benzoyl peroxide\n",
    "Daclatasvir\n",
    "Methoxy polyethylene glycol-epoetin beta\n",
    "Oxygen\n",
    "Protamine sulfate\n",
    "Sodium chloride\n",
    "Artesunate\n",
    "Activated charcoal\n",
    "Procaine benzylpenicillin\n",
    "Zinc sulfate\n",
    "Insulin degludec\n",
    "Rotavirus vaccine\n",
    "Yellow fever vaccine\n",
    "Hepatitis A Vaccine\n",
    "Typhoid Vaccine Live\n",
    "Coal tar\n",
    "Chloroxylenol\n",
    "Calcium gluconate\n",
    "Barium sulfate\n",
    "Pyrantel\n",
    "Dexamethasone isonicotinate\n",
    "Tuberculin purified protein derivative\n",
    "Velpatasvir\n",
    "Hepatitis B Vaccine (Recombinant)\n",
    "Delamanid\n",
    "Tropisetron\n",
    "Nifurtimox\n",
    "Benznidazole\n",
    "Vaborbactam\n",
    "Triclabendazole\n",
    "Fexinidazole\n",
    "Plazomicin\n",
    "Protionamide\n",
    "BCG vaccine\n",
    "Benserazide\n",
    "Melarsoprol\n",
    "Terizidone\n",
    "Atracurium\n",
    "Tacalcitol\n",
    "Meglumine antimoniate\n",
    "Potassium permanganate\n",
    "Fluticasone\n",
    "Pibrentasvir\n",
    "Glecaprevir\n",
    "Estradiol cypionate\n",
    "Typhoid vaccine\n",
    "Lithium carbonate\n",
    "Hydrocortisone aceponate\n",
    "Dabigatran\n",
    "Polymyxin B\n",
    "Cefiderocol\n",
    "Pertussis vaccine\n",
    "Tick-borne encephalitis vaccine (whole virus, inactivated)\n",
    "Ravidasvir\n",
    "Senna leaf\n",
    "Maftivimab\n",
    "Odesivimab\n",
    "Ansuvimab\n",
    "Hepatitis A vaccine (live, attenuated)\n",
    "Japanese Encephalitis Vaccine, Inactivated, Adsorbed\n",
    "Japanese encephalitis vaccine (live, attenuated)\n",
    "Pravastatin\n",
    "Lovastatin\n",
    "Simvastatin\n",
    "Atorvastatin\n",
    "Fluvastatin\n",
    "Rosuvastatin\n",
    "Pitavastatin\n",
    "Mevastatin\n",
    "Tenivastatin\n",
    "Cerivastatin\n",
    "\n",
    "## tag list\n",
    "\n",
    "drug\n",
    "targets\n",
    "target\n",
    "polypeptide\n",
    "go-classifiers\n",
    "go-classifier\n",
    "description\n",
    "category\n",
    "pfams\n",
    "pfam\n",
    "name\n",
    "identifier\n",
    "organism\n",
    "locus\n",
    "amino-acid-sequence\n",
    "external-identifiers\n",
    "external-identifier\n",
    "resource\n",
    "synonyms\n",
    "synonym\n",
    "signal-regions\n",
    "theoretical-pi\n",
    "chromosome-location\n",
    "general-function\n",
    "specific-function\n",
    "molecular-weight\n",
    "gene-name\n",
    "gene-sequence\n",
    "transmembrane-regions\n",
    "cellular-location\n",
    "references\n",
    "articles\n",
    "article\n",
    "citation\n",
    "ref-id\n",
    "pubmed-id\n",
    "attachments\n",
    "attachment\n",
    "title\n",
    "url\n",
    "textbooks\n",
    "textbook\n",
    "isbn\n",
    "links\n",
    "link\n",
    "actions\n",
    "action\n",
    "id\n",
    "name\n",
    "known-action\n",
    "carriers\n",
    "carrier\n",
    "reactions\n",
    "reaction\n",
    "enzymes\n",
    "enzyme\n",
    "uniprot-id\n",
    "drugbank-id\n",
    "right-element\n",
    "left-element\n",
    "snp-adverse-drug-reactions\n",
    "gene-symbol\n",
    "protein-name\n",
    "allele\n",
    "adverse-reaction\n",
    "rs-id\n",
    "enzymes\n",
    "induction-strength\n",
    "inhibition-strength\n",
    "transporters\n",
    "transporter\n",
    "general-references\n",
    "products\n",
    "product\n",
    "ended-marketing-on\n",
    "ndc-product-code\n",
    "ema-ma-number\n",
    "approved\n",
    "dpd-id\n",
    "over-the-counter\n",
    "route\n",
    "ndc-id\n",
    "generic\n",
    "country\n",
    "ema-product-code\n",
    "started-marketing-on\n",
    "source\n",
    "strength\n",
    "fda-application-number\n",
    "labeller\n",
    "dosage-form\n",
    "patents\n",
    "patent\n",
    "pediatric-extension\n",
    "expires\n",
    "number\n",
    "calculated-properties\n",
    "property\n",
    "value\n",
    "kind\n",
    "pathways\n",
    "pathway\n",
    "drugs\n",
    "category\n",
    "smpdb-id\n",
    "sequences\n",
    "sequence\n",
    "snp-effects\n",
    "effect\n",
    "defining-change\n",
    "dosages\n",
    "dosage\n",
    "form\n",
    "protein-binding\n",
    "drug-interactions\n",
    "drug-interaction\n",
    "affected-organisms\n",
    "ahfs-codes\n",
    "packagers\n",
    "packager\n",
    "salts\n",
    "salt\n",
    "monoisotopic-mass\n",
    "cas-number\n",
    "unii\n",
    "average-mass\n",
    "inchikey\n",
    "synthesis-reference\n",
    "mixtures\n",
    "mixture\n",
    "ingredients\n",
    "prices\n",
    "price\n",
    "cost\n",
    "unit\n",
    "international-brands\n",
    "international-brand\n",
    "company\n",
    "fda-label\n",
    "clearance\n",
    "external-links\n",
    "external-link\n",
    "classification\n",
    "alternative-parent\n",
    "class\n",
    "substituent\n",
    "superclass\n",
    "direct-parent\n",
    "kingdom\n",
    "subclass\n",
    "average-mass\n",
    "toxicity\n",
    "food-interactions\n",
    "food-interaction\n",
    "groups\n",
    "group\n",
    "categories\n",
    "category\n",
    "mesh-id\n",
    "state\n",
    "experimental-properties\n",
    "pharmacodynamics\n",
    "monoisotopic-mass\n",
    "manufacturers\n",
    "manufacturer\n",
    "unii\n",
    "cas-number\n",
    "indication\n",
    "atc-codes\n",
    "atc-code\n",
    "level\n",
    "mechanism-of-action\n",
    "volume-of-distribution\n",
    "pdb-entries\n",
    "pdb-entry\n",
    "absorption\n",
    "metabolism\n",
    "half-life\n",
    "msds\n",
    "route-of-elimination\n",
    "\n",
    "Here is the user question: {question}\n",
    "\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "query_rewriter_vs = prompt_vs | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "query_vs = query_rewriter_vs.invoke({\"question\": question})\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The code took {elapsed_time:.2f} seconds to execute.\")\n",
    "print(query_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "bb374394-e828-4246-bfe1-bc3cf7277af5",
   "metadata": {
    "id": "PcA-NQm6tJTz",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH (target)-[r]-(neighbor)\n",
      "WHERE target.id = 'Simvastatin' AND neighbor.id = 'Atorvastatin' \n",
      "RETURN neighbor, r\n",
      "LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "# GraphRAGRewriter\n",
    "\n",
    "model_id = \"meta/llama-3.3-70b-instruct\"\n",
    "\n",
    "# LLM\n",
    "llm = ChatNVIDIA(model=model_id, temperature=0)\n",
    "\n",
    "prompt_graph = PromptTemplate(\n",
    "    template=\n",
    "    \"\"\"you are a graph retriever, and you all be given a user question. please determine which drugs are related to this question, and use the following template to query the graph.\n",
    "cypher template:\n",
    "MATCH (target)-[r]-(neighbor)\n",
    "WHERE target.id = 'drug name 1' AND neighbor.id = 'drug name 2' \n",
    "RETURN neighbor, r\n",
    "LIMIT 1;\n",
    "\n",
    "drug list:\n",
    "Etanercept, Alteplase, Darbepoetin alfa, Goserelin, Pegfilgrastim, Asparaginase Escherichia coli, Desmopressin, Glucagon, Insulin glargine, Rasburicase, Adalimumab, Pegaspargase, Infliximab, Trastuzumab, Rituximab, Streptokinase, Filgrastim, Coagulation Factor IX (Recombinant), Octreotide, Oxytocin, Bevacizumab, Ascorbic acid, Calcitriol, Riboflavin, Thiamine, Ergocalciferol, Folic acid, Pyridoxine, Fluvoxamine, Ramipril, Flunisolide, Lorazepam, Bortezomib, Carbidopa, Fluconazole, Oseltamivir, Erythromycin, Hydroxocobalamin, Pyrimethamine, Azithromycin, Torasemide, Citalopram, Moxifloxacin, Nevirapine, Cladribine, Mesalazine, Cabergoline, Dapsone, Phenytoin, Doxycycline, Clotrimazole, Cycloserine, Metoprolol, Lidocaine, Bleomycin, Chlorambucil, Morphine, Bupivacaine, Tenofovir disoproxil, Tranexamic acid, Chlorthalidone, Valproic acid, Acetaminophen, Gefitinib, Codeine, Piperacillin, Amitriptyline, Hydromorphone, Ethambutol, Metformin, Methadone, Olanzapine, Atenolol, Omeprazole, Pyrazinamide, Cetirizine, Tioguanine, Methylergometrine, Mefloquine, Sulfadiazine, Vinorelbine, Anidulafungin, Clozapine, Levonorgestrel, Timolol, Trihexyphenidyl, Palonosetron, Amlodipine, Carbimazole, Digoxin, Zoledronic acid, Griseofulvin, Mupirocin, Ampicillin, Phenoxymethylpenicillin, Spironolactone, Allopurinol, Ceftazidime, Trimethoprim, Gemcitabine, Entecavir, Betamethasone, Chloramphenicol, Levothyroxine, Loratadine, Quinine, Fluoxetine, Chlorpromazine, Amikacin, Lenalidomide, Cefotaxime, Zidovudine, Oxycodone, Flutamide, Haloperidol, Ritonavir, Vancomycin, Cisplatin, Albendazole, Caspofungin, Oxaliplatin, Erlotinib, Cyclophosphamide, Ciprofloxacin, Vincristine, Fluorouracil, Pyridostigmine, Propylthiouracil, Lamotrigine, Methotrexate, Carbamazepine, Vinblastine, Propranolol, Atropine, Valaciclovir, Lactulose, Voriconazole, Enalapril, Ethosuximide, Amiloride, Oxytetracycline, Thiopental, Linezolid, Ivermectin, Medroxyprogesterone acetate, Chloroquine, Ethionamide, Bisoprolol, Amodiaquine, Rifabutin, Imatinib, Fluphenazine, Testosterone, Efavirenz, Prednisone, Mebendazole, Nystatin, Magnesium sulfate, Latanoprost, Verapamil, Nilutamide, Epinephrine, Sumatriptan, Cefixime, Aprepitant, Tamoxifen, Benzyl benzoate, Losartan, Amphotericin B, Warfarin, Midazolam, Tobramycin, Fludrocortisone, Fluorescein, Daunorubicin, Furosemide, Nitrofurantoin, Naltrexone, Lamivudine, Diethylcarbamazine, Apomorphine, Paroxetine, Norethisterone, Lisinopril, Risperidone, Pentamidine, Hydrocortisone, Mannitol, Deferoxamine, Dolasetron, Clopidogrel, Tetracycline, Meropenem, Potassium chloride, Irinotecan, Methimazole, Mometasone, Clavulanic acid, Etoposide, Sulfasalazine, Gentamicin, Colistin, Indapamide, Tropicamide, Biperiden, Ribavirin, Fentanyl, Propofol, Acetazolamide, Natamycin, Fosfomycin, Diazepam, Mifepristone, Loperamide, Clofazimine, Levamisole, Dacarbazine, Terbinafine, Penicillamine, Prednisolone, Ranitidine, Tacrolimus, Terbutaline, Chlorhexidine, Emtricitabine, Chlorothiazide, Clomifene, Isosorbide dinitrate, Bumetanide, Granisetron, Ondansetron, Tinidazole, Metronidazole, Spectinomycin, Buprenorphine, Misoprostol, Salicylic acid, Salmeterol, Acetylsalicylic acid, Fexofenadine, Isoniazid, Netilmicin, Carboplatin, Methylprednisolone, Telmisartan, Methyldopa, Dactinomycin, Selenium Sulfide, Ethinylestradiol, Cyclopentolate, Formoterol, Glycopyrronium, Cytarabine, Dopamine, Azathioprine, Doxorubicin, Hydrochlorothiazide, Salbutamol, Hydroxyurea, Letrozole, Sulfamethoxazole, Mercaptopurine, Thalidomide, Melphalan, Rifampicin, Abacavir, Ibuprofen, Benzylpenicillin, Praziquantel, Amoxicillin, Fludarabine, Streptomycin, Pilocarpine, Primaquine, Oxamniquine, Flucytosine, Capecitabine, Sertraline, Miconazole, Cefuroxime, Nifedipine, Amiodarone, Diazoxide, Gliclazide, Bicalutamide, Proguanil, Carvedilol, Levofloxacin, Micafungin, Cloxacillin, Bupropion, Halothane, Ofloxacin, Itraconazole, Procarbazine, Arsenic trioxide, Kanamycin, Phenobarbital, Escitalopram, Cyclizine, Ifosfamide, Naloxone, Clindamycin, Bromocriptine, Rifapentine, Levetiracetam, Clarithromycin, Ceftriaxone, Anastrozole, Ketamine, Budesonide, Quetiapine, Enoxaparin, Paclitaxel, Metoclopramide, Dexamethasone, Levodopa, Sevoflurane, Aripiprazole, Clomipramine, Docetaxel, Ergometrine, Dasatinib, Darunavir, Paliperidone, Varenicline, Hydralazine, Carbetocin, Sulfadoxine, Insulin detemir, Cefazolin, Vecuronium, Iohexol, Calcium, Neostigmine, Tiotropium, Ciclesonide, Paromomycin, Everolimus, Cilastatin, Imipenem, Lopinavir, Tazobactam, Deferasirox, Valganciclovir, Hydroxychloroquine, Calcipotriol, Nicotinamide, Acetic acid, Glutaral, Nilotinib, Permethrin, Pretomanid, Silver sulfadiazine, Iodine, Liposomal prostaglandin E1, Sodium stibogluconate, Abiraterone, Acetylcysteine, Rivaroxaban, Eflornithine, Dapagliflozin, Apixaban, Golimumab, Nitrous oxide, Xylometazoline, Artemether, Lumefantrine, Potassium Iodide, Bendamustine, Dalteparin, Dimercaprol, Niclosamide, Raltegravir, Triptorelin, Diloxanide, Nadroparin, Deferiprone, Ulipristal, Asparaginase Erwinia chrysanthemi, Aclidinium, Enzalutamide, Bedaquiline, Certolizumab pegol, Fluticasone furoate, Canagliflozin, Afatinib, Dolutegravir, Sofosbuvir, Bisacodyl, Ledipasvir, Miltefosine, Nivolumab, Pembrolizumab, Empagliflozin, Tedizolid phosphate, Ceftolozane, Ibrutinib, Avibactam, Edoxaban, Umeclidinium, Tetracaine, Chlortetracycline, Benzoyl peroxide, Daclatasvir, Methoxy polyethylene glycol-epoetin beta, Oxygen, Protamine sulfate, Sodium chloride, Artesunate, Activated charcoal, Procaine benzylpenicillin, Zinc sulfate, Insulin degludec, Rotavirus vaccine, Yellow fever vaccine, Hepatitis A Vaccine, Typhoid Vaccine Live, Coal tar, Chloroxylenol, Calcium gluconate, Barium sulfate, Pyrantel, Dexamethasone isonicotinate, Tuberculin purified protein derivative, Velpatasvir, Hepatitis B Vaccine (Recombinant), Delamanid, Tropisetron, Nifurtimox, Benznidazole, Vaborbactam, Triclabendazole, Fexinidazole, Plazomicin, Protionamide, BCG vaccine, Benserazide, Melarsoprol, Terizidone, Atracurium, Tacalcitol, Meglumine antimoniate, Potassium permanganate, Fluticasone, Pibrentasvir, Glecaprevir, Estradiol cypionate, Typhoid vaccine, Lithium carbonate, Hydrocortisone aceponate, Dabigatran, Polymyxin B, Cefiderocol, Pertussis vaccine, \"Tick-borne encephalitis vaccine (whole virus, inactivated)\", Ravidasvir, Senna leaf, Maftivimab, Odesivimab, Ansuvimab, \"Hepatitis A vaccine (live, attenuated)\", \"Japanese Encephalitis Vaccine, Inactivated, Adsorbed\", \"Japanese encephalitis vaccine (live, attenuated)\"\n",
    "\n",
    "\n",
    "here are the question from user: {question}\n",
    "\n",
    "NOTICE THAT GIVE ME THE CYPHER QUERY ONLY. IF THERE ARE NO QUERY MATCH, RETRUN \"\" WITHOUT ANY EXPLANATION.PLEASE DO NOT USE THE DRUGS THAT NOT IN THE LIST.\n",
    "\n",
    "IF THERE IS NOT ANY MATCH DRUG IN LIST, RETRUN  .\n",
    "\n",
    "DO NOT ADD ```.\n",
    "\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    "    \n",
    ")\n",
    "\n",
    "query_rewriter = prompt_graph | llm | StrOutputParser()\n",
    "\n",
    "graph_query = query_rewriter.invoke({\"question\": question})\n",
    "\n",
    "print(graph_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "ff399f81-3e74-446e-a448-046adbda4eb4",
   "metadata": {
    "id": "PcA-NQm6tJTz",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT T1.name, T2.genesymbol, T2.pgkbcalevel, T2.pgxtesting, T3.symbol, T3.functionmethods, T3.notesondiplotype FROM drug AS T1 INNER JOIN pair AS T2 ON T1.drugid = T2.drugid INNER JOIN gene AS T3 ON T2.genesymbol = T3.symbol WHERE T1.name = 'simvastatin' AND T2.usedforrecommendation = 1 | drug.name: Name of the drug, pair.genesymbol: Gene symbol involved in the pharmacogenetic relationship, pair.pgkbcalevel: PharmGKB clinical annotation level of evidence for the gene-drug pair, pair.pgxtesting: Details or links about pharmacogenetic testing availability or methods, gene.symbol: Standard symbol for the gene, gene.functionmethods: Methods used to assess gene or protein function, gene.notesondiplotype: Notes or annotations on the gene's diplotype (combination of two haplotypes)\n"
     ]
    }
   ],
   "source": [
    "# SQLRAGRewriter\n",
    "\n",
    "# LLM\n",
    "llm = ChatNVIDIA(model=model_id, temperature=0)\n",
    "\n",
    "prompt_sql = PromptTemplate(\n",
    "    template=f\"\"\"\n",
    "You are a pharmacist and data engineer, and the following are the cols and explanations in sqlite3 database. DO NOT MODIFIY THE COLUMN NAMES!\n",
    "\n",
    "Table : drug\n",
    "Columns:\n",
    "drugid: Unique identifier for the drug within the CPIC database.\n",
    "name: Name of the drug, typically the generic name.\n",
    "pharmgkbid: Reference to the PharmGKB ID, a database identifier for pharmacogenomics information.\n",
    "rxnormid: RxNorm identifier, a standardized nomenclature for clinical drugs by the National Library of Medicine.\n",
    "drugbankid: Identifier for the drug in DrugBank, a bioinformatics and cheminformatics resource.\n",
    "atcid: Anatomical Therapeutic Chemical (ATC) classification system code for the drug.\n",
    "umlscui: Concept Unique Identifier from the Unified Medical Language System (UMLS).\n",
    "flowchart: Link or reference to a CPIC guideline flowchart associated with the drug.\n",
    "version: Version of the data or record for tracking updates.\n",
    "guidelineid: Identifier for the CPIC guideline(s) associated with the drug.\n",
    "\n",
    "\n",
    "Table : pair\n",
    "Columns:\n",
    "pairid: Unique identifier for the gene-drug pair within the CPIC database.\n",
    "genesymbol: Gene symbol involved in the pharmacogenetic relationship (e.g., CYP2C19).\n",
    "drugid: Reference to the associated drug from the drug table.\n",
    "guidelineid: Identifier for the associated CPIC guideline.\n",
    "usedforrecommendation: Boolean or flag indicating if the pair is used for specific clinical recommendations.\n",
    "version: Version of the pair's record for tracking updates.\n",
    "cpiclevel: CPIC level of evidence for the gene-drug pair (e.g., A, B, C).\n",
    "pgkbcalevel: PharmGKB clinical annotation level of evidence for the gene-drug pair.\n",
    "pgxtesting: Details or links about pharmacogenetic testing availability or methods.\n",
    "citations: References to literature or data sources supporting the gene-drug pair information.\n",
    "removed: Boolean or flag indicating whether the pair was removed from CPIC guidelines.\n",
    "removeddate: Date the pair was removed from the guidelines.\n",
    "removedreason: Reason for removal, such as updated evidence or redundancy.\n",
    "\n",
    "\n",
    "Table : gene\n",
    "Columns:\n",
    "symbol: Standard symbol for the gene (e.g., CYP2D6).\n",
    "chr: Chromosome where the gene is located.\n",
    "genesequenceid: Identifier for the gene sequence, often referencing databases like GenBank.\n",
    "proteinsequenceid: Identifier for the protein sequence produced by the gene.\n",
    "chromosequenceid: Identifier for the chromosomal sequence where the gene resides.\n",
    "mrnasequenceid: Identifier for the mRNA sequence of the gene.\n",
    "hgncid: HGNC (HUGO Gene Nomenclature Committee) ID for the gene.\n",
    "ncbiid: Identifier for the gene in NCBI’s Gene database.\n",
    "ensemblid: Ensembl database identifier for the gene.\n",
    "pharmgkbid: PharmGKB ID for the gene.\n",
    "frequencymethods: Methods used to determine allele or phenotype frequencies.\n",
    "lookupmethod: Methodology for identifying the gene in clinical or research settings.\n",
    "version: Version of the gene's record for tracking updates.\n",
    "notesondiplotype: Notes or annotations on the gene's diplotype (combination of two haplotypes).\n",
    "url: Link to more information about the gene.\n",
    "functionmethods: Methods used to assess gene or protein function.\n",
    "notesonallelenaming: Notes or annotations on how alleles for the gene are named.\n",
    "includephenotypefrequencies: Boolean or flag indicating if phenotype frequencies are included for the gene.\n",
    "includediplotypefrequencies: Boolean or flag indicating if diplotype frequencies are included for the gene.\n",
    "\n",
    "\n",
    "Table : allele\n",
    "Columns:\n",
    "id: Unique identifier for the allele.\n",
    "version: Version of the allele record.\n",
    "genesymbol: Symbol for the associated gene (e.g., CYP2D6).\n",
    "name: Name of the allele.\n",
    "functionalstatus: Functional status of the allele (e.g., normal, decreased, or increased function).\n",
    "clinicalfunctionalstatus: Clinical interpretation of the allele's functional status.\n",
    "clinicalfunctionalsubstrate: Specific substrate relevant to the allele's clinical functional status.\n",
    "activityvalue: Activity score associated with the allele.\n",
    "definitionid: Identifier linking to the allele definition.\n",
    "citations: References or sources supporting the allele data.\n",
    "strength: Strength of evidence for the allele data.\n",
    "functioncomments: Comments or notes about the allele’s function.\n",
    "findings: Observed findings related to the allele.\n",
    "frequency: Population frequency of the allele.\n",
    "inferredfrequency: Inferred frequency based on available data\n",
    "\n",
    "\n",
    "\n",
    "Table : allele_definition\n",
    "Columns:\n",
    "id: Unique identifier for the allele definition.\n",
    "version: Version of the allele definition record.\n",
    "genesymbol: Symbol for the associated gene.\n",
    "name: Name of the allele definition.\n",
    "pharmvarid: Identifier in the PharmVar database.\n",
    "matchesreferencesequence: Indicates whether the allele matches the reference sequence.\n",
    "structuralvariation: Details about structural variations in the allele.\n",
    "allele_frequency\n",
    "alleleid: Identifier for the associated allele.\n",
    "population: Population for which the frequency is reported.\n",
    "frequency: Reported frequency of the allele in the population.\n",
    "label: Label or description for the frequency data.\n",
    "version: Version of the allele frequency record.\n",
    "allele_location_value\n",
    "alleledefinitionid: Identifier for the associated allele definition.\n",
    "locationid: Identifier for the genomic location.\n",
    "variantallele: Details about the variant allele at the location.\n",
    "version: Version of the location value record.\n",
    "\n",
    "\n",
    "Table : gene_result\n",
    "Columns:\n",
    "id: Unique identifier for the gene result record.\n",
    "genesymbol: Symbol for the associated gene.\n",
    "result: Reported result for the gene (e.g., genotype or phenotype).\n",
    "activityscore: Activity score for the gene result.\n",
    "ehrpriority: Priority level for integration into Electronic Health Records (EHR).\n",
    "consultationtext: Text for clinical consultation based on the gene result.\n",
    "version: Version of the gene result record.\n",
    "frequency: Frequency of the result in the population.\n",
    "\n",
    "\n",
    "Table : gene_result_diplotype\n",
    "Columns:\n",
    "id: Unique identifier for the gene result diplotype record.\n",
    "functionphenotypeid: Identifier for the associated functional phenotype.\n",
    "diplotype: Combination of haplotypes for a gene.\n",
    "diplotypekey: Key used to identify the diplotype.\n",
    "frequency: Frequency of the diplotype in the population.\n",
    "\n",
    "\n",
    "\n",
    "Table : guideline\n",
    "Columns:\n",
    "id: Unique identifier for the guideline.\n",
    "version: Version of the guideline record.\n",
    "name: Name of the guideline.\n",
    "url: Link to the guideline document.\n",
    "pharmgkbid: PharmGKB identifier for the guideline.\n",
    "genes: List of genes associated with the guideline.\n",
    "notesonusage: Notes or comments on the guideline's usage.\n",
    "\n",
    "\n",
    "Table : population\n",
    "Columns:\n",
    "id: Unique identifier for the population record.\n",
    "publicationid: Identifier for the associated publication.\n",
    "ethnicity: Ethnic group of the population.\n",
    "population: Name of the population group.\n",
    "populationinfo: Additional information about the population.\n",
    "subjecttype: Type of subjects included in the study.\n",
    "subjectcount: Number of subjects in the population.\n",
    "version: Version of the population record.\n",
    "\n",
    "\n",
    "Table : recommendation\n",
    "Columns:\n",
    "id: Unique identifier for the recommendation.\n",
    "guidelineid: Identifier for the associated guideline.\n",
    "drugid: Identifier for the drug associated with the recommendation.\n",
    "implications: Clinical implications of the recommendation.\n",
    "drugrecommendation: Specific drug recommendation.\n",
    "classification: Classification of the recommendation.\n",
    "phenotypes: Phenotypes relevant to the recommendation.\n",
    "activityscore: Activity score associated with the recommendation.\n",
    "allelestatus: Status of alleles related to the recommendation.\n",
    "lookupkey: Key used for lookup in related databases.\n",
    "population: Population for which the recommendation applies.\n",
    "comments: Additional comments on the recommendation.\n",
    "version: Version of the recommendation record.\n",
    "dosinginformation: Specific dosing information.\n",
    "alternatedrugavailable: Indicates if alternate drugs are available.\n",
    "otherprescribingguidance: Additional guidance for prescribing.\n",
    "\n",
    "\n",
    "\n",
    "Now, you will be given a user question. Based on the tables and columns provided above, please write an SQLite3 query to retrieve and select all the relative column(s) from the tables to answer the question. All drug names are in lowercase.\n",
    "Before you generate the SQL, ENSURE THAT EACH COLUMN YOU USE IS IN THE CORRECT TABLE AND NOT FROM ANOTHER. DO NOT MODIFY THE COLUMN NAMES! THERE IS NO COLUMN NAMED 'cpilevel'; THE CORRECT COLUMN NAME IS 'cpiclevel'. DO NOT ADD ```sql``` IN THE SQL QUERY\n",
    "\n",
    "notice that please give me the sql query ONLY first, then give the explanation for each column you select in format like table_name.column_name: explanation. Seperate these two part by '|', and do not provide any other text. DO NOT USE 'NOT NULL' TO SELECT ROWS\n",
    "here are the question from user: {question}\n",
    "\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "query_rewriter = prompt_sql | llm | StrOutputParser()\n",
    "\n",
    "sql_query = query_rewriter.invoke({\"question\": question})\n",
    "sql_query = sql_query.replace(\"\\n\", \"\").replace(\"cpilevel\", \"cpiclevel\")\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V0SQQ7nk6cr5",
   "metadata": {
    "id": "V0SQQ7nk6cr5",
    "tags": []
   },
   "source": [
    "# Need 3 RAG systems here ->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0bd675-7179-4dba-9195-a357c51bb671",
   "metadata": {
    "id": "Jw4zYbKaIlci"
   },
   "source": [
    "## Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "abf18fcd-c7cc-4646-847d-d9d0017e700e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Loading Embedding Function\n",
    "model_name = \"all-MiniLM-L6-v2.gguf2.f16.gguf\"\n",
    "gpt4all_kwargs = {'allow_download': 'True'}\n",
    "GPT4AllEmbeddings(\n",
    "    model_name=model_name,\n",
    "    gpt4all_kwargs=gpt4all_kwargs,\n",
    ")\n",
    "\n",
    "# Loading Vectorstore（Persisted data used.）\n",
    "\n",
    "persist_directory=\"./Trial_chroma_langchain\"\n",
    "collection_name = \"Trial_v1\"\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=GPT4AllEmbeddings(\n",
    "    model_name=model_name,\n",
    "    gpt4all_kwargs=gpt4all_kwargs,\n",
    "    ),\n",
    "    persist_directory=persist_directory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "7bf590b8-1760-4bf9-8631-e0ebdcced080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_drug_and_tag(input_string):\n",
    "    try:\n",
    "        # Split the input string by the colon\n",
    "        drug, tag = input_string.split(\":\", 1)\n",
    "        return {\"drug\": drug.strip(), \"tag\": tag.strip()}\n",
    "    except ValueError:\n",
    "        # Handle cases where the input is not in the expected format\n",
    "        return {\"error\": \"Input must be in the format 'A:B'\"}\n",
    "\n",
    "q_vs = extract_drug_and_tag(query_vs)\n",
    " # Output: {'drug': 'Simvastatin', 'tag': 'Relevance'}\n",
    "\n",
    "# 現在可直接使用 vectorstore 的檢索功能\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "\n",
    "tag = q_vs['tag']\n",
    "# tag = \"lipitor\"\n",
    "# tag = \"articles\"\n",
    "drug = q_vs['drug']\n",
    "\n",
    "\n",
    "if len(drug) == 0:\n",
    "    query = f\"{tag} :\"\n",
    "    results = retriever.invoke(query)\n",
    "    # print(len(results))\n",
    "    print(results[0])\n",
    "else:\n",
    "    query = f\"\\\"{tag}: information\\\"\"\n",
    "    results = vectorstore.similarity_search(query, filter={\"drug_name\": f\"{drug}\"}, k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b719c93a-5960-4d5c-b6a2-4814ed405e46",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GraphRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6bf5fc-ec64-4799-a26f-81237f436dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "export JAVA_HOME=../GraphRAG/java/jdk-21.0.5\n",
    "../GraphRAG/opt/neo4j-community-5.26.0/bin/neo4j-admin dbms set-initial-password password\n",
    "../GraphRAG/opt/neo4j-community-5.26.0/bin/neo4j start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deeb47a-5ffc-47e7-9f96-cad2d28dafcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "daad3064-bc0f-422b-be82-397fa0b1ffd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simvastatin may decrease the excretion rate of Atorvastatin which could result in a higher serum level.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"password\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "def query_database(query):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        res = []\n",
    "        for record in result:\n",
    "            res.append(record)\n",
    "        return res\n",
    "\n",
    "if (len(graph_query) != 0):\n",
    "    graph_result = query_database(graph_query)\n",
    "driver.close()\n",
    "\n",
    "if (len(graph_query) != 0 and len(graph_result) != 0):\n",
    "    graph_result = graph_result[0][\"r\"][\"description\"]\n",
    "    print(graph_result)\n",
    "else:\n",
    "    graph_result = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff0823-e598-466a-8ebb-502ae5d78409",
   "metadata": {},
   "source": [
    "## TabularRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "cae816e4-b0d1-4ea8-b2a2-65642a1845b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('simvastatin', 'SLCO1B1', '1A', None, 'SLCO1B1', None, None)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('drug.db')\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(sql_query.split(\"|\")[0])\n",
    "sql_result = cursor.fetchall()\n",
    "print(sql_result)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8La0EY8G4GVO",
   "metadata": {
    "id": "8La0EY8G4GVO",
    "tags": []
   },
   "source": [
    "## Fuse info from 3 different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "c8hxNYKiy8u1",
   "metadata": {
    "id": "c8hxNYKiy8u1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Filter\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "model_id = 'meta/llama-3.1-405b-instruct' #\"meta/llama3.3-70b-instruct\"\n",
    "\n",
    "# LLM\n",
    "llm = ChatNVIDIA(model=model_id, temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance\n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question,\n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "vectorstore_info = \"\"\n",
    "\n",
    "for drug in results:\n",
    "    vectorstore_info += drug.page_content\n",
    "\n",
    "    \n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_Tab = Document(\n",
    "    page_content=str(sql_result).replace(\"\\'\", \"\") + str(sql_query.split(\"|\", 1)[1]).replace(\"\\'\", \"\"),\n",
    "    metadata={\"source\": \"TabularRAG\"}\n",
    ")\n",
    "\n",
    "document_vs = Document(\n",
    "    page_content=vectorstore_info,\n",
    "    metadata={\"source\": \"vectorstore\"}\n",
    ")\n",
    "\n",
    "docs = [document_Tab, document_vs]\n",
    "\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": docs}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "bXa4Jaths5UW",
   "metadata": {
    "id": "bXa4Jaths5UW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['documents', 'question'], input_types={}, partial_variables={}, template=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance\\n    of retrieved documents to a user question. If a piece of document contains keywords related to the user question,\\n    keep it. If it does not contain keywords related to the user question, disregard it. The goal is to filter out erroneous retrievals. \\n\\n    Provide the remaining documents as a strict JSON object with a single key 'filtered docs' and no premable or explanation.\\n     <|eot_id|><|start_header_id|>user<|end_header_id|>\\n    Here are the retrieved documents: \\n\\n {documents} \\n\\n\\n    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n    \") middle=[ChatNVIDIA(base_url='https://integrate.api.nvidia.com/v1', model='meta/llama-3.1-405b-instruct', temperature=0.0)] last=JsonOutputParser()\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Filter\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "model_id = 'meta/llama-3.1-405b-instruct' #\"meta/llama3.3-70b-instruct\"\n",
    "\n",
    "# LLM\n",
    "llm = ChatNVIDIA(model=model_id, temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance\n",
    "    of retrieved documents to a user question. If a piece of document contains keywords related to the user question,\n",
    "    keep it. If it does not contain keywords related to the user question, disregard it. The goal is to filter out erroneous retrievals. \\n\n",
    "    Provide the remaining documents as a strict JSON object with a single key 'filtered docs' and no premable or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the retrieved documents: \\n\\n {documents} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "\n",
    "\n",
    "retrieval_filter = prompt | llm | JsonOutputParser()\n",
    "documents = docs\n",
    "\n",
    "filtered_retrieval = retrieval_filter.invoke({\"question\": question, \"documents\": documents})\n",
    "print(retrieval_filter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tkaVHCBD1WlJ",
   "metadata": {
    "id": "tkaVHCBD1WlJ"
   },
   "source": [
    "## Nvidia Re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "dad3da3c-eb51-4a6b-96c2-6a7d85faef80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = list()\n",
    "\n",
    "for f in filtered_retrieval['filtered docs']:\n",
    "    t = Document(page_content=f[\"page_content\"])\n",
    "    temp.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "HUJoAimUp86D",
   "metadata": {
    "id": "HUJoAimUp86D",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'relevance_score': -1.888671875}, page_content='For patients with the SLCO1B1*5 genotype, a maximum daily dose of 20mg of simvastatin is recommended to avoid adverse effects from the increased exposure to the drug, such as muscle pain and risk of rhabdomyolysis.[F4658]'),\n",
       " Document(metadata={'relevance_score': -2.841796875}, page_content='Following an oral dose of 14C-labeled simvastatin in man, 13% of the dose was excreted in urine and 60% in feces.[F4655,F4658]')]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Nvidia ReRanker\n",
    "from langchain_nvidia_ai_endpoints import NVIDIARerank\n",
    "ranker = NVIDIARerank(model= \"nvidia/llama-3.2-nv-rerankqa-1b-v1\", truncate=\"END\") #model=\"nvidia/nv-rerankqa-mistral-4b-v3\"\n",
    "#api_key=\"$API_KEY_REQUIRED_IF_EXECUTING_OUTSIDE_NGC\"\n",
    "\n",
    "all_docs = temp # filtered vectorstore + graph + sql\n",
    "\n",
    "ranker.top_n = 5\n",
    "docs = ranker.compress_documents(query=query, documents=all_docs)\n",
    "docs ### it should still contain the tags for vec, kg and sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VrjvrJ3__YnC",
   "metadata": {
    "id": "VrjvrJ3__YnC"
   },
   "source": [
    "# Answer the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "8JFQu_0kDLjG",
   "metadata": {
    "id": "8JFQu_0kDLjG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"meta/llama-3.3-70b-instruct\"\n",
    "\n",
    "# LLM\n",
    "llm = ChatNVIDIA(model=model_id, temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are a top professional medical doctor at Stanford. You have previously obtained pieces of medication context from a vectorstore, a knowledge graph, and a SQL database. Your goal is to answer medication-related questions from patients as accurately and factually as possible.\n",
    "If you don't have sufficient information or knowledge to answer, respond with: \"I don't have enough information to answer this question.\"\n",
    "\n",
    "Below are suggested reasoning steps to use internally before you present your final answer. You must not reveal these steps to the user or mention that you have a reasoning process. These steps are for your own chain-of-thought:\n",
    "\n",
    "1. **Identify Key Information**: Identify the key medication(s) or condition(s) the patient is asking about.\n",
    "\n",
    "2. **Identify Types of Information Needed**: Determine the type of information requested: side effects, dosage, drug interactions, indication, mechanism of action, route of elimination, toxicity, food interactions, or adverse drug reactions.\n",
    "\n",
    "3. **Assess Data Sources**: Consider which data sources (vectorstore (vc), knowledge graph (kg), SQL database (sql)) would be most relevant for the query at hand, even if you won't actually retrieve the data.\n",
    "   (a) Consult vectorstore data for general medication background.\n",
    "   (b) If the question involves how one drug relates to another drug (e.g., drug interactions, not food interactions), check the knowledge graph data.\n",
    "   (c) If the question involves standardized data (e.g., drug to gene relationship information), check the SQL database.\n",
    "\n",
    "4. **Formulate Steps for Information Gathering**:\n",
    "   - **Drug Interactions**: Outline steps to check for known drug interactions, contraindications, or safety precautions.\n",
    "   - **Dosage Information**: Detail the process to verify the recommended dosages, considering patient factors like age, weight, or existing conditions.\n",
    "   - **Side Effects**: List steps to gather known side effects, their prevalence, and severity.\n",
    "   - **Indication**: Identify the approved uses of the medication.\n",
    "   - **Mechanism of Action**: Describe how the drug works at a molecular or biochemical level.\n",
    "   - **Route of Elimination**: Determine the primary routes by which the drug is removed from the body.\n",
    "   - **Toxicity**: Assess any known toxic effects or overdose symptoms.\n",
    "   - **Food Interactions**: Check for any interactions between the medication and food or dietary components.\n",
    "   - **Adverse Drug Reactions**: Gather information on adverse reactions reported with the drug.\n",
    "\n",
    "5. **Synthesize Information**: Integrate information from all sources, ensuring consistency and accuracy.\n",
    "\n",
    "6. **Provide Answer or Disclaimer**:\n",
    "   - If sufficient data can be synthesized and confident with the information, provide a direct, evidence-based answer.\n",
    "   - If there's not enough information available or not confident, state so explicitly.\n",
    "\n",
    "Return your answer as a strict JSON object with a single key \"answer.\"\n",
    "\n",
    "Example:\n",
    "For a question like: \"Can I take ibuprofen with aspirin?\"\n",
    "\n",
    "Internal reasoning:\n",
    "\n",
    " - Identify that the query is about drug interactions between ibuprofen and aspirin.\n",
    " - Consider checking a knowledge graph for known drug interactions.\n",
    " - Look for common side effects or contraindications when these drugs are combined.\n",
    " - Evaluate if there are any specific patient conditions or warnings to consider.\n",
    " - Synthesize the information to determine if it's safe to take ibuprofen with aspirin.\n",
    "\n",
    "A possible JSON might be:\n",
    "{{\n",
    "    \"answer: 'It's generally safe to take ibuprofen with aspirin, but monitor for increased risk of bleeding or stomach irritation. However, always consult with a healthcare provider for your specific case.'\"\n",
    "}}\n",
    "\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "rag_chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "43403e65-76c6-4030-8aac-95a75b5d68d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Are there specific formulations of Simvastatin designed for patients with genetic risks?'"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "b02e9dbb-48eb-42d4-a1cb-888cc32c6faf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'There are no specific formulations of Simvastatin designed for patients with genetic risks, but dosing recommendations vary based on genetic factors. For patients with the SLCO1B1*5 genotype, a maximum daily dose of 20mg of simvastatin is recommended to minimize the risk of adverse effects such as muscle pain and rhabdomyolysis.'}"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd59cdf-a04d-4b2e-b9cc-6a1b1e80a6c6",
   "metadata": {
    "id": "ccd59cdf-a04d-4b2e-b9cc-6a1b1e80a6c6"
   },
   "source": [
    "Implement these as a control flow in LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ZnOXNVJq9w1",
   "metadata": {
    "id": "8ZnOXNVJq9w1"
   },
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "### State\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    three_queries: List[str]\n",
    "    documents: List[str]\n",
    "\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "### Nodes\n",
    "\n",
    "def query_rewriter(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    three_queries = query_rewriter.invoke(question)\n",
    "    return {\"three_queries\": three_queries, \"question\": question}\n",
    "    # return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "    three_queries = state[\"three_queries\"]\n",
    "\n",
    "    # Retrieval\n",
    "    vc = retriever.invoke(three_queries[0])\n",
    "    kg = retriever.invoke(three_queries[1])\n",
    "    sql = retriever.invoke(three_queries[2])\n",
    "    documents = {\"vc\": vc, \"kg\": kg, \"sql\": sql}\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # # Score each doc\n",
    "    # filtered_docs = []\n",
    "    # web_search = \"No\"\n",
    "    # for t in documents:\n",
    "    #   for d in t:\n",
    "    #     score = retrieval_grader.invoke(\n",
    "    #         {\"question\": question, \"document\": d.page_content}\n",
    "    #     )\n",
    "    #     grade = score[\"score\"]\n",
    "    #     # Document relevant\n",
    "    #     if grade.lower() == \"yes\":\n",
    "    #         print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "    #         filtered_docs.append(d)\n",
    "    #     # Document not relevant\n",
    "    #     else:\n",
    "    #         print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "    #         # We do not include the document in filtered_docs\n",
    "    #         # We set a flag to indicate that we want to run web search\n",
    "    #         # web_search = \"Yes\"\n",
    "    #         # continue\n",
    "    # return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "    for section, doc_list in documents.items():\n",
    "        # Initialize the list for the current key in filtered_docs\n",
    "        filtered_docs[section] = []\n",
    "        print(f\"Processing section: {section} with {len(doc_list)} documents.\")\n",
    "\n",
    "        for doc in doc_list:\n",
    "            # Determine the content to pass to the retrieval grader\n",
    "            # Attempt to extract 'page_content'; if unavailable, use a string representation of the entire document\n",
    "            document_content = doc.get(\"page_content\", None)\n",
    "            if document_content is None:\n",
    "                # Option 1: Use the entire document serialized as a JSON string\n",
    "                import json\n",
    "                document_content = json.dumps(doc)\n",
    "                print(f\"---INFO: 'page_content' not found for Document ID {doc.get('doc_id', 'N/A')}. Using serialized document content.\")\n",
    "\n",
    "            # Invoke the retrieval grader with the question and document content\n",
    "            score = retrieval_grader.invoke(\n",
    "                {\"question\": question, \"document\": document_content}\n",
    "            )\n",
    "            grade = score.get(\"score\", \"\").lower()\n",
    "\n",
    "            # Check if the grade is 'yes' indicating relevance\n",
    "            if grade == \"yes\":\n",
    "                print(f\"---GRADE: Document ID {doc.get('doc_id', 'N/A')} is RELEVANT---\")\n",
    "                filtered_docs[section].append(doc)\n",
    "            else:\n",
    "                print(f\"---GRADE: Document ID {doc.get('doc_id', 'N/A')} is NOT RELEVANT---\")\n",
    "    return {\n",
    "        \"documents\": filtered_docs,\n",
    "        \"question\": question,\n",
    "    }\n",
    "\n",
    "def rerank (state):\n",
    "    \"\"\"\n",
    "    Rerank documents from vectorstore, kg, and sql\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---rerank---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Rerank\n",
    "    # all_docs = documents # filtered vectorstore + graph + sql\n",
    "    # docs = ranker.compress_documents(query=query, documents=all_docs)\n",
    "\n",
    "    ranker.top_n = 3\n",
    "    reranked_docs = {}\n",
    "\n",
    "    # Iterate through each category in documents\n",
    "    for category, doc_list in documents.items():\n",
    "        print(f\"\\nReranking category: '{category}'\")\n",
    "\n",
    "        if not doc_list:\n",
    "            print(f\"---INFO: No documents found in category '{category}'. Skipping reranking.\")\n",
    "            reranked_docs[category] = []\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Rerank documents within the current category\n",
    "            # Assuming 'ranker.compress_documents' accepts 'query' and 'documents' as arguments\n",
    "            # and returns a list of documents sorted by relevance.\n",
    "            reranked_list = ranker.compress_documents(query=question, documents=doc_list)\n",
    "\n",
    "            # Assign the reranked list directly without limiting to top_n\n",
    "            reranked_docs[category] = reranked_list\n",
    "\n",
    "            print(f\"---INFO: Reranked {len(reranked_list)} documents for category '{category}'.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"---ERROR: Failed to rerank documents in category '{category}'. Error: {e}\")\n",
    "            # Optionally, retain the original documents in case of failure\n",
    "            reranked_docs[category] = doc_list  # or set to [] if preferred\n",
    "\n",
    "    return {\"documents\": reranked_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    # return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def web_search(state):\n",
    "#     \"\"\"\n",
    "#     Web search based based on the question\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): Appended web results to documents\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---WEB SEARCH---\")\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"]\n",
    "\n",
    "#     # Web search\n",
    "#     docs = web_search_tool.invoke({\"query\": question})\n",
    "#     web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "#     web_results = Document(page_content=web_results)\n",
    "#     if documents is not None:\n",
    "#         documents.append(web_results)\n",
    "#     else:\n",
    "#         documents = [web_results]\n",
    "#     return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "### Conditional edge\n",
    "\n",
    "\n",
    "# def route_question(state):\n",
    "#     \"\"\"\n",
    "#     Route question to web search or RAG.\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         str: Next node to call\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---ROUTE QUESTION---\")\n",
    "#     question = state[\"question\"]\n",
    "#     print(question)\n",
    "#     source = question_router.invoke({\"question\": question})\n",
    "#     print(source)\n",
    "#     print(source[\"datasource\"])\n",
    "#     if source[\"datasource\"] == \"web_search\":\n",
    "#         print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "#         return \"websearch\"\n",
    "#     elif source[\"datasource\"] == \"vectorstore\":\n",
    "#         print(\"---ROUTE QUESTION TO RAG---\")\n",
    "#         return \"vectorstore\"\n",
    "\n",
    "\n",
    "# def decide_to_generate(state):\n",
    "#     \"\"\"\n",
    "#     Determines whether to generate an answer, or add web search\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         str: Binary decision for next node to call\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "#     question = state[\"question\"]\n",
    "#     web_search = state[\"web_search\"]\n",
    "#     filtered_documents = state[\"documents\"]\n",
    "\n",
    "#     if web_search == \"Yes\":\n",
    "#         # All documents have been filtered check_relevance\n",
    "#         # We will re-generate a new query\n",
    "#         print(\n",
    "#             \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\"\n",
    "#         )\n",
    "#         return \"websearch\"\n",
    "#     else:\n",
    "#         # We have relevant documents, so generate answer\n",
    "#         print(\"---DECISION: GENERATE---\")\n",
    "#         return \"generate\"\n",
    "\n",
    "\n",
    "### Conditional edge\n",
    "\n",
    "\n",
    "# def grade_generation_v_documents_and_question(state):\n",
    "#     \"\"\"\n",
    "#     Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         str: Decision for next node to call\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---CHECK HALLUCINATIONS---\")\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"]\n",
    "#     generation = state[\"generation\"]\n",
    "\n",
    "#     score = hallucination_grader.invoke(\n",
    "#         {\"documents\": documents, \"generation\": generation}\n",
    "#     )\n",
    "#     grade = score[\"score\"]\n",
    "\n",
    "#     # Check hallucination\n",
    "#     if grade == \"yes\":\n",
    "#         print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "#         # Check question-answering\n",
    "#         print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "#         score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "#         grade = score[\"score\"]\n",
    "#         if grade == \"yes\":\n",
    "#             print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "#             return \"useful\"\n",
    "#         else:\n",
    "#             print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "#             return \"not useful\"\n",
    "#     else:\n",
    "#         print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "#         return \"not supported\"\n",
    "\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "# workflow.add_node(\"websearch\", web_search)  # web search\n",
    "workflow.add_node(\"query_rewriter\", query_rewriter)  # query rewriter\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"rerank\", rerank)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa3d08-6a86-4705-a28b-e2721070bc5e",
   "metadata": {
    "id": "07fa3d08-6a86-4705-a28b-e2721070bc5e"
   },
   "outputs": [],
   "source": [
    "# from typing_extensions import TypedDict\n",
    "# from typing import List, Annotated\n",
    "# import operator\n",
    "# # from langgraph.graph.message import add_messages\n",
    "\n",
    "# ### State\n",
    "\n",
    "# class GraphState(TypedDict):\n",
    "#     \"\"\"\n",
    "#     Represents the state of our graph.\n",
    "\n",
    "#     Attributes:\n",
    "#         question: question\n",
    "#         generation: LLM generation\n",
    "#         web_search: whether to add search\n",
    "#         documents: list of documents\n",
    "#     \"\"\"\n",
    "#     question : str\n",
    "#     generation : str\n",
    "#     web_search : str\n",
    "#     # documents : List[str]\n",
    "#     documents : Annotated[List[str], operator.add]\n",
    "\n",
    "# # Define initial_state\n",
    "# initial_state = GraphState(\n",
    "#     question=\"\",\n",
    "#     generation=\"\",\n",
    "#     web_search=\"No\",\n",
    "#     documents=[],\n",
    "#     #memory=memory,\n",
    "# )\n",
    "\n",
    "# from langchain.schema import Document\n",
    "\n",
    "# ### Nodes\n",
    "\n",
    "# def retrieve(state):\n",
    "#     \"\"\"\n",
    "#     Retrieve documents from vectorstore\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): New key added to state, documents, that contains retrieved documents\n",
    "#     \"\"\"\n",
    "#     print(\"---RETRIEVE---\")\n",
    "#     question = state[\"question\"]\n",
    "\n",
    "#     # Retrieval\n",
    "#     documents = retriever.invoke(question)\n",
    "#     return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "# def generate(state):\n",
    "#     \"\"\"\n",
    "#     Generate answer using RAG on retrieved documents\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): New key added to state, generation, that contains LLM generation\n",
    "#     \"\"\"\n",
    "#     print(\"---GENERATE---\")\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"][-4:]\n",
    "\n",
    "#     # RAG generation\n",
    "#     generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "#     return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "# def grade_documents(state):\n",
    "#     \"\"\"\n",
    "#     Determines whether the retrieved documents are relevant to the question\n",
    "#     If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"][-4:]\n",
    "\n",
    "#     # Score each doc\n",
    "#     filtered_docs = []\n",
    "#     web_search = \"No\"\n",
    "#     for d in documents[:4]: #for d in documents:\n",
    "#         score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "#         grade = score['score']\n",
    "#         print(d)\n",
    "#         # Document relevant\n",
    "#         if grade.lower() == \"yes\":\n",
    "#             print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "#             filtered_docs.append(d)\n",
    "#         # Document not relevant\n",
    "#         else:\n",
    "#             print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "#             # We do not include the document in filtered_docs\n",
    "#             # We set a flag to indicate that we want to run web search\n",
    "#             # web_search = \"Yes\"\n",
    "#             continue\n",
    "#     if not filtered_docs:\n",
    "#       web_search = \"Yes\"\n",
    "#     return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n",
    "# def web_search(state):\n",
    "#     \"\"\"\n",
    "#     Web search based based on the question\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): Appended web results to documents\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---WEB SEARCH---\")\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"][-4:]\n",
    "\n",
    "#     # Web search\n",
    "#     docs = web_search_tool.run(({question}))#({\"query\": question})\n",
    "#     # docs = web_search_tool.invoke({\"query\": question})\n",
    "\n",
    "\n",
    "#     # Handle the docs as a list\n",
    "\n",
    "#     web_results = \"\\n\".join([d for d in docs.split('...')])\n",
    "#     web_results = Document(page_content=web_results)\n",
    "\n",
    "#     # web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "#     # web_results = Document(page_content=web_results)\n",
    "\n",
    "#     if documents is not None:\n",
    "#         documents.append(web_results)\n",
    "#     else:\n",
    "#         documents = [web_results]\n",
    "\n",
    "\n",
    "#     print(web_results)\n",
    "#     print(documents) ### test\n",
    "#     return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "# ### Conditional edge\n",
    "\n",
    "# def route_question(state):\n",
    "#     \"\"\"\n",
    "#     Route question to web search or RAG.\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         str: Next node to call\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---ROUTE QUESTION---\")\n",
    "#     question = state[\"question\"]\n",
    "#     print(question)\n",
    "#     source = question_router.invoke({\"question\": question})\n",
    "#     print(source)\n",
    "#     print(source['datasource'])\n",
    "#     if source['datasource'] == 'web_search':\n",
    "#         print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "#         return \"websearch\"\n",
    "#     elif source['datasource'] == 'vectorstore':\n",
    "#         print(\"---ROUTE QUESTION TO RAG---\")\n",
    "#         return \"vectorstore\"\n",
    "\n",
    "# def decide_to_generate(state):\n",
    "#     \"\"\"\n",
    "#     Determines whether to generate an answer, or add web search\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         str: Binary decision for next node to call\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "#     question = state[\"question\"]\n",
    "#     web_search = state[\"web_search\"]\n",
    "#     filtered_documents = state[\"documents\"][-4:] #\n",
    "\n",
    "#     if web_search == \"Yes\":\n",
    "#         # All documents have been filtered check_relevance\n",
    "#         # We will re-generate a new query\n",
    "#         print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n",
    "#         return \"websearch\"\n",
    "#     else:\n",
    "#         # We have relevant documents, so generate answer\n",
    "#         print(\"---DECISION: GENERATE---\")\n",
    "#         return \"generate\"\n",
    "\n",
    "# ### Conditional edge\n",
    "\n",
    "# def grade_generation_v_documents_and_question(state):\n",
    "#     \"\"\"\n",
    "#     Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         str: Decision for next node to call\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---CHECK HALLUCINATIONS---\")\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"][-4:]\n",
    "#     generation = state[\"generation\"] #\n",
    "\n",
    "#     score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "#     grade = score['score']\n",
    "\n",
    "#     # Check hallucination\n",
    "#     if grade == \"yes\":\n",
    "#         print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "#         # Check question-answering\n",
    "#         print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "#         score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "#         grade = score['score']\n",
    "#         if grade == \"yes\":\n",
    "#             print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "#             return \"useful\"\n",
    "#         else:\n",
    "#             print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "#             return \"not useful\"\n",
    "#     else:\n",
    "#         print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "#         return \"not supported\"\n",
    "\n",
    "# from langgraph.graph import END, StateGraph\n",
    "# workflow = StateGraph(GraphState)\n",
    "\n",
    "# # Define the nodes\n",
    "# workflow.add_node(\"websearch\", web_search) # web search\n",
    "# workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
    "# workflow.add_node(\"grade_documents\", grade_documents) # grade documents\n",
    "# workflow.add_node(\"generate\", generate) # generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f21594-00d4-48a8-ae2e-4e55a010b540",
   "metadata": {
    "id": "73f21594-00d4-48a8-ae2e-4e55a010b540"
   },
   "source": [
    "### Graph Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lfZpwEriFKyG",
   "metadata": {
    "id": "lfZpwEriFKyG"
   },
   "outputs": [],
   "source": [
    "# Build graph\n",
    "\n",
    "# Set the entry point to the first node\n",
    "workflow.add_edge(START, \"query_rewriter\")\n",
    "\n",
    "# Define the sequential flow between nodes\n",
    "workflow.add_edge(\"query_rewriter\", \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"rerank\")\n",
    "workflow.add_edge(\"rerank\", \"grade_documents\")\n",
    "workflow.add_edge(\"grade_documents\", \"generate\")\n",
    "\n",
    "# Define the end of the workflow\n",
    "workflow.add_edge(\"generate\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4b9e4-3ba8-47d6-958c-e5a7112ac6f4",
   "metadata": {
    "id": "d9a4b9e4-3ba8-47d6-958c-e5a7112ac6f4"
   },
   "outputs": [],
   "source": [
    "# # Build graph\n",
    "# workflow.set_conditional_entry_point(\n",
    "#     route_question,\n",
    "#     {\n",
    "#         \"websearch\": \"websearch\",\n",
    "#         \"vectorstore\": \"retrieve\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"grade_documents\",\n",
    "#     decide_to_generate,\n",
    "#     {\n",
    "#         \"websearch\": \"websearch\",\n",
    "#         \"generate\": \"generate\",\n",
    "#     },\n",
    "# )\n",
    "# workflow.add_edge(\"websearch\", \"generate\")\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"generate\",\n",
    "#     grade_generation_v_documents_and_question,\n",
    "#     {\n",
    "#         \"not supported\": \"generate\",\n",
    "#         \"useful\": END,\n",
    "#         \"not useful\": \"websearch\",\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d733ab80-7e7b-4b1a-9519-9242de647eda",
   "metadata": {
    "id": "d733ab80-7e7b-4b1a-9519-9242de647eda"
   },
   "source": [
    "Trace:\n",
    "\n",
    "https://smith.langchain.com/public/8d449b67-6bc4-4ecf-9153-759cd21df24f/r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PJhxqIbzE5D-",
   "metadata": {
    "id": "PJhxqIbzE5D-"
   },
   "source": [
    "# **Adding Memory to the Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uVuTOwb0FFHA",
   "metadata": {
    "id": "uVuTOwb0FFHA"
   },
   "outputs": [],
   "source": [
    "# The checkpointer lets the graph persist its state\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GvoxupAhFE_i",
   "metadata": {
    "id": "GvoxupAhFE_i"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "_printed = set()\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": \"0\", #thread_id,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P1tuYjnYxSBU",
   "metadata": {
    "id": "P1tuYjnYxSBU"
   },
   "source": [
    "# **Single Cell Agent Flow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2BLapu5ojm9a",
   "metadata": {
    "id": "2BLapu5ojm9a"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# # import streamlit as st\n",
    "# import pandas as pd\n",
    "# import openai\n",
    "# from langchain.schema import Document\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "# from typing_extensions import TypedDict\n",
    "# from typing import List\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "# from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "# from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langgraph.graph import END, StateGraph\n",
    "# import gradio as gr\n",
    "\n",
    "# # Define tools\n",
    "# os.environ['SERPER_API_KEY'] = \"4bf2ebebf278aeef645193a533a3b94d7b011e17\"\n",
    "# serper_api_key = os.getenv('SERPER_API_KEY')\n",
    "# web_search_tool = GoogleSerperAPIWrapper(api_key=serper_api_key, k=10)\n",
    "\n",
    "# # Initialize ChatOpenAI\n",
    "# openai.api_key = \"sk-proj-M8297PbB5Nekd64YyBlpT3BlbkFJA5xRy149A4ceEcmke54P\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.5)\n",
    "\n",
    "# # Initialize GPT4AllEmbeddings\n",
    "# model_name = \"all-MiniLM-L6-v2.gguf2.f16.gguf\"\n",
    "# gpt4all_kwargs = {'allow_download': 'True'}\n",
    "# embeddings = GPT4AllEmbeddings(\n",
    "#     model_name=model_name,\n",
    "#     gpt4all_kwargs=gpt4all_kwargs\n",
    "# )\n",
    "\n",
    "# # Load the CSV file\n",
    "# csv_file_path = \"./UniFi_Help_Articles_Formatted.csv\"\n",
    "# df = pd.read_csv(csv_file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# # Convert text data to LangChain Document format\n",
    "# docs_list = [Document(page_content=text) for text in df['body'].tolist()]\n",
    "\n",
    "# # Split the text into smaller chunks\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "#     chunk_size=700, chunk_overlap=100\n",
    "# )\n",
    "# doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# # Add to vectorDB\n",
    "# vectorstore = Chroma.from_documents(\n",
    "#     documents=doc_splits,\n",
    "#     collection_name=\"rag-chroma\",\n",
    "#     embedding=GPT4AllEmbeddings(model_name=model_name, gpt4all_kwargs=gpt4all_kwargs),\n",
    "# )\n",
    "# retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "# ### Define tools ###\n",
    "\n",
    "# ### Retrieval Grader\n",
    "\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "\n",
    "# # LLM GPT-4o\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"\"\"system\n",
    "#     You are a grader assessing relevance of a retrieved document to a user question. Please note that every user question is about Ubiquiti's *UniFi* consoles or devices or software service even if not explicitly specified.\n",
    "#     If the document contains certain words / keywords related to the user question or the same words appeared in the user question, make sure to grade it as relevant (yes).\n",
    "#     It does not need to be a stringent test. The goal is to accurately filter out erroneous retrievals and keep the correct retrievals. Give a binary 'yes' or 'no' score to indicate whether the document is relevant to the question or not.\n",
    "#     Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "\n",
    "#     user\n",
    "#     Here is the retrieved document: {document}\n",
    "#     Here is the user question: {question}\n",
    "\n",
    "#     assistant\"\"\",\n",
    "#     input_variables=[\"question\", \"document\"],\n",
    "# )\n",
    "\n",
    "# retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "\n",
    "# ### Generate\n",
    "\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain import hub\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# # Prompt\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"\"\"system\n",
    "#     You are an assistant for question-answering tasks. Use the following pieces of retrieved context to carefully answer the question by staying grounded in the facts/context and being relevant.\n",
    "#     Please note that every user question is about Ubiquiti's *UniFi* consoles or devices or software service even if not explicitly specified.\n",
    "#     Check the urls in the context and make sure they do not contain any parenthesis (Remove the parenthesis and any url link inside them when you generate answers).\n",
    "#     If you don't know the answer or don't see relevant keywords in the context, just say that you don't know. Use ten sentences maximum and keep the answer concise.\n",
    "\n",
    "#     user\n",
    "#     Question: {question}\n",
    "#     Context: {context}\n",
    "#     Answer:\n",
    "\n",
    "#     assistant\"\"\",\n",
    "#     input_variables=[\"question\", \"context\"],\n",
    "# )\n",
    "\n",
    "# # Post-processing\n",
    "# def format_docs(docs):\n",
    "#     return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# # Chain\n",
    "# rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# ### Hallucination Grader\n",
    "\n",
    "# # Prompt\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"\"\"system\n",
    "#     You are a good grader assessing whether an answer is grounded in / supported by a set of facts / documents fetched.\n",
    "#     Please note that every user question is about Ubiquiti's *UniFi* consoles or devices or software service even if not explicitly specified.\n",
    "#     Give a binary 'yes' or 'no' score to indicate whether the answer is grounded in / supported by the documents / facts provided or not.\n",
    "#     Look at all the documents / facts carefully and understand everything about the answer and the documents.\n",
    "#     Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "\n",
    "#     user\n",
    "#     Here are the facts:\n",
    "#     -------\n",
    "#     {documents}\n",
    "#     -------\n",
    "#     Here is the answer: {generation}\n",
    "\n",
    "#     assistant\"\"\",\n",
    "#     input_variables=[\"generation\", \"documents\"],\n",
    "# )\n",
    "\n",
    "# hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "\n",
    "# ### Answer Grader\n",
    "\n",
    "# # Prompt\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"\"\"system\n",
    "#     You are a grader assessing whether an answer is useful to resolve a question. Please note that every user question is about Ubiquiti's *UniFi* consoles or devices or software service even if not explicitly specified.\n",
    "#     Give a binary 'yes' or 'no' to indicate whether the answer is useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "\n",
    "#     user\n",
    "#     Here is the answer:\n",
    "#     -------\n",
    "#     {generation}\n",
    "#     -------\n",
    "#     Here is the question: {question}\n",
    "\n",
    "#     assistant\"\"\",\n",
    "#     input_variables=[\"generation\", \"question\"],\n",
    "# )\n",
    "\n",
    "# answer_grader = prompt | llm | JsonOutputParser()\n",
    "\n",
    "# ### Router\n",
    "\n",
    "# ### Original Prompt for GPT-4o\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# ### Original Prompt for GPT-4o\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"\"\"system\n",
    "#     You are an expert at routing a user question to a vectorstore or web search. Use the vectorstore for questions on UniFi products / consoles / sevices, etc. Pay special attention to devices like Dream Machine.\n",
    "#     You do not need to be stringent with the keywords in the question related to these topics.Otherwise, use web search. Give a binary choice 'web_search' or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and no preamble or explanation.\n",
    "\n",
    "#     user\n",
    "#     Question to route: {question}\n",
    "\n",
    "#     assistant\"\"\",\n",
    "#     input_variables=[\"question\"],\n",
    "# )\n",
    "\n",
    "# question_router = prompt | llm | JsonOutputParser()\n",
    "\n",
    "\n",
    "# ### Google Search\n",
    "# import os\n",
    "# from langchain.schema import Document\n",
    "# from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "# os.environ['SERPER_API_KEY'] = \"4bf2ebebf278aeef645193a533a3b94d7b011e17\"\n",
    "# # Initialize the Serper search tool with your API key\n",
    "# serper_api_key = os.getenv('SERPER_API_KEY')\n",
    "# web_search_tool = GoogleSerperAPIWrapper(api_key=serper_api_key, k=10)\n",
    "\n",
    "# from typing_extensions import TypedDict\n",
    "# from typing import List\n",
    "\n",
    "# ### State\n",
    "\n",
    "# class GraphState(TypedDict):\n",
    "#     \"\"\"\n",
    "#     Represents the state of our graph.\n",
    "\n",
    "#     Attributes:\n",
    "#         question: question\n",
    "#         generation: LLM generation\n",
    "#         web_search: whether to add search\n",
    "#         documents: list of documents\n",
    "#     \"\"\"\n",
    "#     question : str\n",
    "#     generation : str\n",
    "#     web_search : str\n",
    "#     documents : List[str]\n",
    "\n",
    "# # Define initial_state\n",
    "# initial_state = GraphState(\n",
    "#     question=\"\",\n",
    "#     generation=\"\",\n",
    "#     web_search=\"No\",\n",
    "#     documents=[],\n",
    "#     #memory=memory,\n",
    "# )\n",
    "\n",
    "# from langchain.schema import Document\n",
    "\n",
    "# ### Nodes\n",
    "\n",
    "# def retrieve(state):\n",
    "#     \"\"\"\n",
    "#     Retrieve documents from vectorstore\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): New key added to state, documents, that contains retrieved documents\n",
    "#     \"\"\"\n",
    "#     print(\"---RETRIEVE---\")\n",
    "#     question = state[\"question\"]\n",
    "\n",
    "#     # Retrieval\n",
    "#     documents = retriever.invoke(question)\n",
    "#     return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "# def generate(state):\n",
    "#     \"\"\"\n",
    "#     Generate answer using RAG on retrieved documents\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): New key added to state, generation, that contains LLM generation\n",
    "#     \"\"\"\n",
    "#     print(\"---GENERATE---\")\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"]\n",
    "\n",
    "#     # RAG generation\n",
    "#     generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "#     return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "# def grade_documents(state):\n",
    "#     \"\"\"\n",
    "#     Determines whether the retrieved documents are relevant to the question\n",
    "#     If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"]\n",
    "\n",
    "#     # Score each doc\n",
    "#     filtered_docs = []\n",
    "#     web_search = \"No\"\n",
    "#     for d in documents:\n",
    "#         score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "#         grade = score['score']\n",
    "#         print(d)\n",
    "#         # Document relevant\n",
    "#         if grade.lower() == \"yes\":\n",
    "#             print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "#             filtered_docs.append(d)\n",
    "#         # Document not relevant\n",
    "#         else:\n",
    "#             print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "#             # We do not include the document in filtered_docs\n",
    "#             # We set a flag to indicate that we want to run web search\n",
    "#             # web_search = \"Yes\"\n",
    "#             continue\n",
    "#     if not filtered_docs:\n",
    "#       web_search = \"Yes\"\n",
    "#     return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n",
    "# def web_search(state):\n",
    "#     \"\"\"\n",
    "#     Web search based based on the question\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): Appended web results to documents\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---WEB SEARCH---\")\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"]\n",
    "\n",
    "#     # Web search\n",
    "#     docs = web_search_tool.run(({question}))#({\"query\": question})\n",
    "#     # docs = web_search_tool.invoke({\"query\": question})\n",
    "\n",
    "\n",
    "#     # Handle the docs as a list\n",
    "\n",
    "#     web_results = \"\\n\".join([d for d in docs.split('...')])\n",
    "#     web_results = Document(page_content=web_results)\n",
    "\n",
    "#     # web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "#     # web_results = Document(page_content=web_results)\n",
    "\n",
    "#     if documents is not None:\n",
    "#         documents.append(web_results)\n",
    "#     else:\n",
    "#         documents = [web_results]\n",
    "\n",
    "\n",
    "#     print(web_results)\n",
    "#     print(documents) ### test\n",
    "#     return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "# ### Conditional edge\n",
    "\n",
    "# def route_question(state):\n",
    "#     \"\"\"\n",
    "#     Route question to web search or RAG.\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         str: Next node to call\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---ROUTE QUESTION---\")\n",
    "#     question = state[\"question\"]\n",
    "#     print(question)\n",
    "#     source = question_router.invoke({\"question\": question})\n",
    "#     print(source)\n",
    "#     print(source['datasource'])\n",
    "#     if source['datasource'] == 'web_search':\n",
    "#         print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "#         return \"websearch\"\n",
    "#     elif source['datasource'] == 'vectorstore':\n",
    "#         print(\"---ROUTE QUESTION TO RAG---\")\n",
    "#         return \"vectorstore\"\n",
    "\n",
    "# def decide_to_generate(state):\n",
    "#     \"\"\"\n",
    "#     Determines whether to generate an answer, or add web search\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         str: Binary decision for next node to call\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "#     question = state[\"question\"]\n",
    "#     web_search = state[\"web_search\"]\n",
    "#     filtered_documents = state[\"documents\"]\n",
    "\n",
    "#     if web_search == \"Yes\":\n",
    "#         # All documents have been filtered check_relevance\n",
    "#         # We will re-generate a new query\n",
    "#         print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n",
    "#         return \"websearch\"\n",
    "#     else:\n",
    "#         # We have relevant documents, so generate answer\n",
    "#         print(\"---DECISION: GENERATE---\")\n",
    "#         return \"generate\"\n",
    "\n",
    "# ### Conditional edge\n",
    "\n",
    "# def grade_generation_v_documents_and_question(state):\n",
    "#     \"\"\"\n",
    "#     Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         str: Decision for next node to call\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"---CHECK HALLUCINATIONS---\")\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"]\n",
    "#     generation = state[\"generation\"]\n",
    "\n",
    "#     score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "#     grade = score['score']\n",
    "\n",
    "#     # Check hallucination\n",
    "#     if grade == \"yes\":\n",
    "#         print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "#         # Check question-answering\n",
    "#         print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "#         score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "#         grade = score['score']\n",
    "#         if grade == \"yes\":\n",
    "#             print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "#             return \"useful\"\n",
    "#         else:\n",
    "#             print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "#             return \"not useful\"\n",
    "#     else:\n",
    "#         print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "#         return \"not supported\"\n",
    "\n",
    "# from langgraph.graph import END, StateGraph\n",
    "# workflow = StateGraph(GraphState)\n",
    "\n",
    "# # Define the nodes\n",
    "# workflow.add_node(\"websearch\", web_search) # web search\n",
    "# workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
    "# workflow.add_node(\"grade_documents\", grade_documents) # grade documents\n",
    "# workflow.add_node(\"generate\", generate) # generatae\n",
    "\n",
    "# workflow.set_conditional_entry_point(\n",
    "#     route_question,\n",
    "#     {\n",
    "#         \"websearch\": \"websearch\",\n",
    "#         \"vectorstore\": \"retrieve\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"grade_documents\",\n",
    "#     decide_to_generate,\n",
    "#     {\n",
    "#         \"websearch\": \"websearch\",\n",
    "#         \"generate\": \"generate\",\n",
    "#     },\n",
    "# )\n",
    "# workflow.add_edge(\"websearch\", \"generate\")\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"generate\",\n",
    "#     grade_generation_v_documents_and_question,\n",
    "#     {\n",
    "#         \"not supported\": \"generate\",\n",
    "#         \"useful\": END,\n",
    "#         \"not useful\": \"websearch\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# # # The checkpointer lets the graph persist its state\n",
    "# # from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "# memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "# config = {\n",
    "#     \"configurable\": {\n",
    "#         # Checkpoints are accessed by thread_id\n",
    "#         \"thread_id\": \"1\", #thread_id,\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # Replace with your key\n",
    "\n",
    "# # llm = ChatOpenAI(temperature=0.5, model='gpt-4o')\n",
    "\n",
    "# # def predict(message):\n",
    "# #     # history_langchain_format = []\n",
    "# #     # for human, ai in history:\n",
    "# #     #     history_langchain_format.append(HumanMessage(content=human))\n",
    "# #     #     history_langchain_format.append(AIMessage(content=ai))\n",
    "# #     # history_langchain_format.append(HumanMessage(content=message))\n",
    "\n",
    "# #     inputs = {\n",
    "# #         \"question\": message,\n",
    "# #     }\n",
    "# #     for output in app.stream(inputs, config, stream_mode=\"values\"):\n",
    "# #       results = output\n",
    "\n",
    "# #     gpt_response = results[\"generation\"]#llm(history_langchain_format)\n",
    "# #     return gpt_response #gpt_response.content\n",
    "\n",
    "# # gr.ChatInterface(predict).launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1nLuBpf4xJS-",
   "metadata": {
    "id": "1nLuBpf4xJS-"
   },
   "source": [
    "# **Running the chatbot with gradio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y8KDj4yLKlnU",
   "metadata": {
    "id": "y8KDj4yLKlnU"
   },
   "outputs": [],
   "source": [
    "# from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "# memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "# abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kEjQWo0wKleB",
   "metadata": {
    "id": "kEjQWo0wKleB"
   },
   "outputs": [],
   "source": [
    "# messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "# thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "# async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "#     kind = event[\"event\"]\n",
    "#     if kind == \"on_chat_model_stream\":\n",
    "#         content = event[\"data\"][\"chunk\"].content\n",
    "#         if content:\n",
    "#             # Empty content in the context of OpenAI means\n",
    "#             # that the model is asking for a tool to be invoked.\n",
    "#             # So we only print non-empty content\n",
    "#             print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bvIMKoUwCrDK",
   "metadata": {
    "id": "bvIMKoUwCrDK"
   },
   "outputs": [],
   "source": [
    "app = workflow.compile()\n",
    "\n",
    "def predict(message):\n",
    "\n",
    "    inputs = {\n",
    "        \"question\": message,\n",
    "    }\n",
    "\n",
    "    results = None\n",
    "    try:\n",
    "        for output in app.stream(inputs, config, stream_mode=\"values\"):\n",
    "            results = output\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered: {e}\")\n",
    "        results = {\"generation\": [\"Sorry, something went wrong. Please try again later.\"]}\n",
    "\n",
    "    gpt_response = [\"Sorry, I am not able to answer this question.\"]\n",
    "    if results.get(\"generation\"):\n",
    "        gpt_response = results[\"generation\"]\n",
    "    return gpt_response\n",
    "\n",
    "predict(\"\")\n",
    "\n",
    "# gr.ChatInterface(predict).launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RRVLI06AC9Xd",
   "metadata": {
    "id": "RRVLI06AC9Xd"
   },
   "source": [
    "## gradio implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mun2qhCAluDB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3335329,
     "status": "ok",
     "timestamp": 1718728013669,
     "user": {
      "displayName": "Donald Lu",
      "userId": "11995103325229826253"
     },
     "user_tz": -480
    },
    "id": "Mun2qhCAluDB",
    "outputId": "19606a1c-cd95-4d57-b177-e310b30f4675"
   },
   "outputs": [],
   "source": [
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "def predict(message, history):\n",
    "\n",
    "    inputs = {\n",
    "        \"question\": message,\n",
    "    }\n",
    "\n",
    "    results = None\n",
    "    try:\n",
    "        for output in app.stream(inputs, config, stream_mode=\"values\"):\n",
    "            results = output\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered: {e}\")\n",
    "        results = {\"generation\": [\"Sorry, something went wrong. Please try again later.\"]}\n",
    "\n",
    "    gpt_response = [\"Sorry, I am not able to answer this question.\"]\n",
    "    if results.get(\"generation\"):\n",
    "        gpt_response = results[\"generation\"]\n",
    "    return gpt_response\n",
    "\n",
    "gr.ChatInterface(predict).launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CrjxKoINrsfq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CrjxKoINrsfq",
    "outputId": "c92bbe0d-b04b-4438-9f2b-8a06fdb7654c"
   },
   "outputs": [],
   "source": [
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "def predict(message, history):\n",
    "    # history_langchain_format = []\n",
    "    # for human, ai in history:\n",
    "    #     history_langchain_format.append(HumanMessage(content=human))\n",
    "    #     history_langchain_format.append(AIMessage(content=ai))\n",
    "    # history_langchain_format.append(HumanMessage(content=message)\n",
    "\n",
    "    inputs = {\n",
    "        \"question\": message,\n",
    "    }\n",
    "    for output in app.stream(inputs, config, stream_mode=\"values\"):\n",
    "      results = output\n",
    "\n",
    "    gpt_response = [\"Sorry, I am not able to answer this question.\"]\n",
    "    if results[\"generation\"]:\n",
    "        gpt_response = results[\"generation\"]#llm(history_langchain_format)\n",
    "    return gpt_response #gpt_response.content\n",
    "\n",
    "gr.ChatInterface(predict).launch(share=True, debug=True) #(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7QSvC-JN6IY_",
   "metadata": {
    "id": "7QSvC-JN6IY_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "PJhxqIbzE5D-",
    "P1tuYjnYxSBU"
   ],
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1EoZ34IIAJjlZ5x6r-_INn-wak7dG3-5e",
     "timestamp": 1734616923435
    },
    {
     "file_id": "1JXmEBEfDHfvTnvTO2a-qQj_c6vMndzxq",
     "timestamp": 1734003831531
    },
    {
     "file_id": "1PffSt8m5NCv7hmK4VIC2c9oejzvp0akw",
     "timestamp": 1718756167358
    },
    {
     "file_id": "1lUrXJQnK0SUp1tGVbD9e3frJ4jNaqNXj",
     "timestamp": 1718622402186
    },
    {
     "file_id": "1_ECrNmOPeabaTIhI7LwH5GJ50Yy3csiH",
     "timestamp": 1718036531450
    },
    {
     "file_id": "15v1PrR1dJkF8aqVKu6SioT2hXuo84qf0",
     "timestamp": 1718031514344
    },
    {
     "file_id": "1_mMcKXY9A8jAnlucFk8XIVc8R3_642dB",
     "timestamp": 1717670140937
    },
    {
     "file_id": "1BcxixnGGJNTYDB65aRvnSjcHtA7pPs0M",
     "timestamp": 1716933249563
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
